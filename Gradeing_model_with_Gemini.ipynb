{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import TextLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Initialize AWS Textract client\n",
    "textract = boto3.client('textract', region_name='us-east-1')  # Change region if needed\n",
    "\n",
    "# Convert PDF to images\n",
    "pdf_path = \"22101A0029 - Assignment 111.pdf\"  # Replace with your PDF file\n",
    "output_folder = \"pdf\"  # Folder to save images temporarily\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "images = convert_from_path(pdf_path, dpi=300)  # Convert PDF to high-resolution images\n",
    "\n",
    "extracted_text = \"\"  # Variable to store extracted text\n",
    "\n",
    "# Process each image\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(output_folder, f\"page_{i+1}.png\")\n",
    "    image.save(image_path, \"PNG\")  # Save image temporarily\n",
    "\n",
    "    # Read image bytes\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_bytes = img_file.read()\n",
    "\n",
    "    # Extract text using Textract\n",
    "    response = textract.detect_document_text(Document={'Bytes': image_bytes})\n",
    "\n",
    "    # Store extracted text\n",
    "    for item in response[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            extracted_text += item[\"Text\"] + \"\\n\"\n",
    "\n",
    "    # Delete the image immediately after processing\n",
    "    os.remove(image_path)\n",
    "\n",
    "# Remove the empty folder after all images are deleted\n",
    "if not os.listdir(output_folder):\n",
    "    os.rmdir(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "# Load environment variables (Ensure API keys are set)\n",
    "os.environ['HF_TOKEN'] = \"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\" \n",
    "\n",
    "# Create text embeddings and vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert extracted text into a LangChain Document object\n",
    "doc = Document(page_content=extracted_text)\n",
    "\n",
    "# Use a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents([doc])  # Pass as a list of Document objects\n",
    "\n",
    "# Create a vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "gemini_api_key = \"AIzaSyD4AJnu6NLQaISQvtCkqb-SK4TrV5ZRLiI\"\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=gemini_api_key, model=\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an AI teacher grading a student's assignment based on quality, accuracy, and completeness.\\n\\n\"\n",
    "    \"Instructions:\\n\"\n",
    "    \"1. If the student's name is not found in the retrieved content, assign a grade of 0/10.\\n\"\n",
    "    \"2. Otherwise, provide a grade from [4/10, 6/10, 8/10, or 10/10] based on the assignment quality.\\n\"\n",
    "    \"3. Always return the response in the format:\\n\"\n",
    "    \"   **Grade:** X/10\\n\"\n",
    "    \"   **Feedback:** [Provide 1-2 lines of constructive feedback on how the student can improve.]\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Student Name: {input}\\n\\nStudent Assignment:\\n{context}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Grade:** 8/10\n",
      "**Feedback:** The assignment is well-structured and covers the key aspects of ethics in AI. To improve, consider providing real-world examples to illustrate your points and enhance clarity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs(student_name):\n",
    "    retrieved_docs = retriever.invoke(student_name)  # Retrieve related assignment\n",
    "    context_list = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # Check if any retrieved document actually contains the student's name\n",
    "    if not any(student_name in doc for doc in context_list):\n",
    "        return \"\"  # Return empty to indicate no relevant document found\n",
    "    \n",
    "    return \"\\n\\n\".join(context_list)  # Convert to string if relevant doc found\n",
    "\n",
    "def generate_grade_and_feedback(student_name):\n",
    "    context = get_relevant_docs(student_name)\n",
    "    \n",
    "    if not context.strip():  # If no relevant documents found\n",
    "        return \"**Grade:** 0/10\\n**Feedback:** No assignment found for this student.\"\n",
    "    \n",
    "    # Format the prompt correctly before passing it to LLM\n",
    "    messages = prompt.format_messages(input=student_name, context=context)\n",
    "    \n",
    "    # Pass the formatted messages to the LLM\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content  # Extract text response from LLM output\n",
    "\n",
    "# Example usage:\n",
    "result = generate_grade_and_feedback(\"Pratik\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
