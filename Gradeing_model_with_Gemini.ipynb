{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.document_loaders import TextLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Initialize AWS Textract client\n",
    "textract = boto3.client('textract', region_name='us-east-1')  # Change region if needed\n",
    "\n",
    "# Convert PDF to images\n",
    "pdf_path = \"22101A0029 - Assignment 111.pdf\"  # Replace with your PDF file\n",
    "output_folder = \"pdf\"  # Folder to save images temporarily\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "images = convert_from_path(pdf_path, dpi=300)  # Convert PDF to high-resolution images\n",
    "\n",
    "extracted_text = \"\"  # Variable to store extracted text\n",
    "\n",
    "# Process each image\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(output_folder, f\"page_{i+1}.png\")\n",
    "    image.save(image_path, \"PNG\")  # Save image temporarily\n",
    "\n",
    "    # Read image bytes\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_bytes = img_file.read()\n",
    "\n",
    "    # Extract text using Textract\n",
    "    response = textract.detect_document_text(Document={'Bytes': image_bytes})\n",
    "\n",
    "    # Store extracted text\n",
    "    for item in response[\"Blocks\"]:\n",
    "        if item[\"BlockType\"] == \"LINE\":\n",
    "            extracted_text += item[\"Text\"] + \"\\n\"\n",
    "\n",
    "    # Delete the image immediately after processing\n",
    "    os.remove(image_path)\n",
    "\n",
    "# Remove the empty folder after all images are deleted\n",
    "if not os.listdir(output_folder):\n",
    "    os.rmdir(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SDS\\nPage No.\\nDate\\n/\\n/\\nName: Pratik Jitendra Sawant\\nRoll No: 22101A0029\\nsubject : Ethics in AI\\nAssignment 1\\nQ1\\nEthics in AI and ML is essential for the responsible\\ndevelopment and use of these technologies. It\\nensures\\ni) Fairness: Prevents biases in algorithms, ensuring\\ndecisions are impartial and equitable\\nfor all individuals.\\nii) Transparency: Promotes clarity in how Al systems\\nmake decisions, enabling users to\\nunderstand and trust their process.\\niii) Privacy Protection: Safeguards personal data and\\nensures Al systems respect user\\nprivacy.\\niv) Accountability Establishes clear responsibility\\nfor the actions and outcomes of Al\\nsystems.\\nv) Safety and Well- Being Ensures Al technologies\\nare safe, aligned with\\nhuman values, and do not cause harm to individuals\\nor society.\\nQ2.\\nHere are some strategies to overcome challenges to\\nethical Al:\\ni) Bias Mitigation : Implement diverse, representative\\ndatasets and use techniques like\\nfairness-aware algorithms.\\nii) Transparency & Explainability Develop XAI models that\\nallow users to understand how decisions are made.\\niii) Privacy & Protection: Adopt privacy-preserving techniques,\\nsuch as differential privacy, data\\nanonymization, to protect sensitive user data.\\niv) Accountability and Regulation : Establish clear accountability\\nframeworks & regulatory\\nstandards to ensure responsible Al.\\nv) Continuous Monitoring & Auditing: Regularly au dit AI\\nsystems for ethical\\nconcerns, ensure compliance with standards, and adjust\\nmodels as needed to correct issues.\\nThese strategies can help ensure Al is developed and\\nused responsibly, ethically, and for the benefit of all.\\nQ3.\\nThe dimensions of accountability in AI include :\\ni) Developer Accountability Ensuring ethical design and\\ndevelopment of AI systems,\\nensuring not causing harm.\\nii) Organizational Accountability : Companies ensuring responsi-\\nble deployment and ethical\\nuse of Al.\\nSDS / Page No.\\nDate\\n/\\niii) Legal Accountability Compliance with laws and\\nregulations governing the AI\\nsystems.\\niv) Operational Accountability : Ongoing monitoring to\\nensure ethical Al\\nperformance in real word use.\\nv) User Accountability : Users responsibly interacting\\nwith Al systems and reporting\\nissues.\\nvi) Societal Accountability: Governments ensuring\\nthe creation and enforce-\\nment of ethical AI frameworks.\\nQ4.\\nTransparency in AI/MI is crucial for several\\nreasons:\\ni) Trust and Accountability : Users and stakeholders\\nneed to understand how\\nAl models make decisions to build trust and\\nensure accountability.\\nii) Bias Detection and Fairness: Transparent and\\nhelp identify and mitigate biases, ensuring\\nfairness in decision-making.\\niii) Regulatory Compliance : Many industries require\\nXAI to meet legal and ethical standards.\\niv) Debugging and Improvement - Understanding model decisions\\nallows developers to diagnose\\nerrors and improve performance.\\nv) User Understanding and Control : Transparent Al empowers\\nbno\\nusers to interpret\\npredictions and take appropriate actions.\\nvi) Ethical AI Development : Transparency helps align Al systems\\nwith ethical considerations and\\nsocietal values\\nQ5.\\nDataset Bias occurs when training data is unrepresent\\n-ative or skewed, leading to unfair Al predictions. It can\\narise due to sampling bias, measurement bias, or\\nhistorical bias.\\nWays to reduce Dataset Bias :\\ni) Use Diverse Data: Ensure representation from all groups.\\nii) Balance the Dataset: Apply oversampling, undersampling,or\\naugmentation\\niii) Detect Bias: Use fairness metrics and auditing tools.\\niv) Apply Fairness Algorithms Use de-biasing techniques\\nlike re-weighting.\\nv) Human Oversight: Regularly review data and model\\ndecisions.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "# Load environment variables (Ensure API keys are set)\n",
    "os.environ['HF_TOKEN'] = \"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\" \n",
    "\n",
    "# Create text embeddings and vector store\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert extracted text into a LangChain Document object\n",
    "doc = Document(page_content=extracted_text)\n",
    "\n",
    "# Use a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents([doc])  # Pass as a list of Document objects\n",
    "\n",
    "# Create a vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDS\n",
      "Page No.\n",
      "Date\n",
      "/\n",
      "/\n",
      "Name: Pratik Jitendra Sawant\n",
      "Roll No: 22101A0029\n",
      "subject : Ethics in AI\n",
      "Assignment 1\n",
      "Q1\n",
      "Ethics in AI and ML is essential for the responsible\n",
      "development and use of these technologies. It\n",
      "ensures\n",
      "i) Fairness: Prevents biases in algorithms, ensuring\n",
      "decisions are impartial and equitable\n",
      "for all individuals.\n",
      "ii) Transparency: Promotes clarity in how Al systems\n",
      "make decisions, enabling users to\n",
      "understand and trust their process.\n",
      "iii) Privacy Protection: Safeguards personal data and\n",
      "ensures Al systems respect user\n",
      "privacy.\n",
      "iv) Accountability Establishes clear responsibility\n",
      "for the actions and outcomes of Al\n",
      "systems.\n",
      "v) Safety and Well- Being Ensures Al technologies\n",
      "are safe, aligned with\n",
      "human values, and do not cause harm to individuals\n",
      "or society.\n",
      "Q2.\n",
      "Here are some strategies to overcome challenges to\n",
      "ethical Al:\n",
      "i) Bias Mitigation : Implement diverse, representative\n",
      "datasets and use techniques like\n",
      "fairness-aware algorithms.\n",
      "ii) Transparency & Explainability Develop XAI models that\n",
      "allow users to understand how decisions are made.\n",
      "iii) Privacy & Protection: Adopt privacy-preserving techniques,\n",
      "such as differential privacy, data\n",
      "anonymization, to protect sensitive user data.\n",
      "iv) Accountability and Regulation : Establish clear accountability\n",
      "frameworks & regulatory\n",
      "standards to ensure responsible Al.\n",
      "v) Continuous Monitoring & Auditing: Regularly au dit AI\n",
      "systems for ethical\n",
      "concerns, ensure compliance with standards, and adjust\n",
      "models as needed to correct issues.\n",
      "These strategies can help ensure Al is developed and\n",
      "used responsibly, ethically, and for the benefit of all.\n",
      "Q3.\n",
      "The dimensions of accountability in AI include :\n",
      "i) Developer Accountability Ensuring ethical design and\n",
      "development of AI systems,\n",
      "ensuring not causing harm.\n",
      "ii) Organizational Accountability : Companies ensuring responsi-\n",
      "ble deployment and ethical\n",
      "use of Al.\n",
      "SDS / Page No.\n",
      "Date\n",
      "/\n",
      "iii) Legal Accountability Compliance with laws and\n",
      "regulations governing the AI\n",
      "systems.\n",
      "iv) Operational Accountability : Ongoing monitoring to\n",
      "ensure ethical Al\n",
      "performance in real word use.\n",
      "v) User Accountability : Users responsibly interacting\n",
      "with Al systems and reporting\n",
      "issues.\n",
      "vi) Societal Accountability: Governments ensuring\n",
      "the creation and enforce-\n",
      "ment of ethical AI frameworks.\n",
      "Q4.\n",
      "Transparency in AI/MI is crucial for several\n",
      "reasons:\n",
      "i) Trust and Accountability : Users and stakeholders\n",
      "need to understand how\n",
      "Al models make decisions to build trust and\n",
      "ensure accountability.\n",
      "ii) Bias Detection and Fairness: Transparent and\n",
      "help identify and mitigate biases, ensuring\n",
      "fairness in decision-making.\n",
      "iii) Regulatory Compliance : Many industries require\n",
      "XAI to meet legal and ethical standards.\n",
      "iv) Debugging and Improvement - Understanding model decisions\n",
      "allows developers to diagnose\n",
      "errors and improve performance.\n",
      "v) User Understanding and Control : Transparent Al empowers\n",
      "bno\n",
      "users to interpret\n",
      "predictions and take appropriate actions.\n",
      "vi) Ethical AI Development : Transparency helps align Al systems\n",
      "with ethical considerations and\n",
      "societal values\n",
      "Q5.\n",
      "Dataset Bias occurs when training data is unrepresent\n",
      "-ative or skewed, leading to unfair Al predictions. It can\n",
      "arise due to sampling bias, measurement bias, or\n",
      "historical bias.\n",
      "Ways to reduce Dataset Bias :\n",
      "i) Use Diverse Data: Ensure representation from all groups.\n",
      "ii) Balance the Dataset: Apply oversampling, undersampling,or\n",
      "augmentation\n",
      "iii) Detect Bias: Use fairness metrics and auditing tools.\n",
      "iv) Apply Fairness Algorithms Use de-biasing techniques\n",
      "like re-weighting.\n",
      "v) Human Oversight: Regularly review data and model\n",
      "decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "gemini_api_key = \"AIzaSyD4AJnu6NLQaISQvtCkqb-SK4TrV5ZRLiI\"\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=gemini_api_key, model=\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an AI teacher grading a student's assignment based on quality, accuracy, and completeness.\\n\\n\"\n",
    "    \"Instructions:\\n\"\n",
    "    \"1. If the student's name is not found in the retrieved content, assign a grade of 0/10.\\n\"\n",
    "    \"2. Otherwise, provide a grade from [4/10, 6/10, 8/10, or 10/10] based on the assignment quality.\\n\"\n",
    "    \"3. Always return the response in the format:\\n\"\n",
    "    \"   **Grade:** X/10\\n\"\n",
    "    \"   **Feedback:** [Provide 1-2 lines of constructive feedback on how the student can improve.]\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"Student Name: {input}\\n\\nStudent Assignment:\\n{context}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Grade:** 0/10\n",
      "**Feedback:** No assignment found for this student.\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs(student_name):\n",
    "    retrieved_docs = retriever.invoke(student_name)  # Retrieve related assignment\n",
    "    context_list = [doc.page_content for doc in retrieved_docs]\n",
    "    \n",
    "    # Check if any retrieved document actually contains the student's name\n",
    "    if not any(student_name in doc for doc in context_list):\n",
    "        return \"\"  # Return empty to indicate no relevant document found\n",
    "    \n",
    "    return \"\\n\\n\".join(context_list)  # Convert to string if relevant doc found\n",
    "\n",
    "def generate_grade_and_feedback(student_name):\n",
    "    context = get_relevant_docs(student_name)\n",
    "    \n",
    "    if not context.strip():  # If no relevant documents found\n",
    "        return \"**Grade:** 0/10\\n**Feedback:** No assignment found for this student.\"\n",
    "    \n",
    "    # Format the prompt correctly before passing it to LLM\n",
    "    messages = prompt.format_messages(input=student_name, context=context)\n",
    "    \n",
    "    # Pass the formatted messages to the LLM\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content  # Extract text response from LLM output\n",
    "\n",
    "# Example usage:\n",
    "result = generate_grade_and_feedback(\"Pratik\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
